{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnPcLjV6KOo7"
      },
      "source": [
        "# Multi-Agent Workflow with Weaviate QueryAgent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC-KKwbMKOo8"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/multi_agent_workflow_with_weaviate_queryagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orJLd8aAKOo9"
      },
      "source": [
        "In this example, we will be building a LlamaIndex Agent Workflow that ends up being a multi-agent system that aims to be a Docs Assistant capable of:\n",
        "- Writing new content to a \"LlamaIndexDocs\" collection in Weaviate\n",
        "- Writing new content to a \"WeaviateDocs\" collection in Weaviate\n",
        "- Using the Weaviate [`QueryAgent`](https://weaviate.io/developers/agents/query) to answer questions based on the contents of these collections.\n",
        "\n",
        "The `QueryAgent` is a full agent prodcut by Weaviate, that is capable of doing regular search, as well as aggregations over the collections you give it access to. Our 'orchestrator' agent will decide when to invoke the Weaviate QueryAgent, leaving the job of creating Weaviate specific search queries to it.\n",
        "\n",
        "**Things you will need:**\n",
        "\n",
        "- An OpenAI API key (or switch to another provider and adjust the code below)\n",
        "- A Weaviate sandbox (this is free)\n",
        "- Your Weaviate sandbox URL and API key\n",
        "\n",
        "![Workflow Overview](https://github.com/run-llama/llama_index/blob/main/_static/agents/workflow-weaviate-multiagent.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwWRfTrWKOo9"
      },
      "source": [
        "## Install & Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F3kUXagGKOo9",
        "outputId": "7a5afbea-c4aa-4c15-86fb-010a535c77a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-core\n",
            "  Downloading llama_index_core-0.14.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-utils-workflow\n",
            "  Downloading llama_index_utils_workflow-0.4.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-llms-openai\n",
            "  Downloading llama_index_llms_openai-0.6.5-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-web\n",
            "  Downloading llama_index_readers_web-0.5.5-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting weaviate-client[agents]\n",
            "  Downloading weaviate_client-4.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.13.1)\n",
            "Collecting aiosqlite (from llama-index-core)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.28.1)\n",
            "Collecting llama-index-workflows<3,>=2 (from llama-index-core)\n",
            "  Downloading llama_index_workflows-2.8.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.5.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.11.10)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.32.4)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (0.12.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (4.15.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core) (2.0.0)\n",
            "Collecting pyvis<0.4,>=0.3.2 (from llama-index-utils-workflow)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting validators<1.0.0,>=0.34.0 (from weaviate-client[agents])\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from weaviate-client[agents]) (1.6.5)\n",
            "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client[agents]) (1.75.1)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from weaviate-client[agents]) (5.29.5)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from weaviate-client[agents])\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting weaviate-agents<2.0.0,>=1.0.0 (from weaviate-client[agents])\n",
            "  Downloading weaviate_agents-1.1.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<2,>=1.108.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-openai) (1.109.1)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (4.13.5)\n",
            "Collecting chromedriver-autoinstaller<0.7,>=0.6.3 (from llama-index-readers-web)\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: defusedxml<0.8,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (0.7.1)\n",
            "Collecting firecrawl-py>=4.3.3 (from llama-index-readers-web)\n",
            "  Downloading firecrawl_py-4.5.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting html2text<2025,>=2024.2.26 (from llama-index-readers-web)\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml-html-clean>=0.4.2 (from llama-index-readers-web)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: lxml>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (5.4.0)\n",
            "Collecting markdownify>=1.1.0 (from llama-index-readers-web)\n",
            "  Downloading markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting newspaper3k<0.3,>=0.2.8 (from llama-index-readers-web)\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oxylabs>=2.0.0 (from llama-index-readers-web)\n",
            "  Downloading oxylabs-2.0.0-py3-none-any.whl.metadata (687 bytes)\n",
            "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
            "  Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting selenium<5,>=4.17.2 (from llama-index-readers-web)\n",
            "  Downloading selenium-4.37.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
            "  Downloading spider-client-0.0.27.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-web) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core) (1.22.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.2.1->weaviate-client[agents]) (43.0.3)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-web) (2.8)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from chromedriver-autoinstaller<0.7,>=0.6.3->llama-index-readers-web) (25.0)\n",
            "Collecting wrapt (from llama-index-core)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (1.1.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.12/dist-packages (from firecrawl-py>=4.3.3->llama-index-readers-web) (15.0.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<3,>=2->llama-index-core)\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify>=1.1.0->llama-index-readers-web) (1.17.0)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.108.1->llama-index-llms-openai) (1.3.1)\n",
            "Collecting pyee<14,>=13 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.2.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.8.0->llama-index-core) (0.4.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (4.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.4)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium<5,>=4.17.2->llama-index-readers-web) (1.9.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: httpx-sse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-agents<2.0.0,>=1.0.0->weaviate-client[agents]) (0.4.3)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from weaviate-agents<2.0.0,>=1.0.0->weaviate-client[agents]) (13.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->weaviate-agents<2.0.0,>=1.0.0->weaviate-client[agents]) (4.0.0)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
            "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (3.20.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web) (2.4.0)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium<5,>=4.17.2->llama-index-readers-web)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.2.1->weaviate-client[agents]) (2.0.0)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.2.1->weaviate-client[agents]) (2.23)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.8.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->weaviate-agents<2.0.0,>=1.0.0->weaviate-client[agents]) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis<0.4,>=0.3.2->llama-index-utils-workflow) (0.2.14)\n",
            "Downloading llama_index_core-0.14.5-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_utils_workflow-0.4.1-py3-none-any.whl (7.7 kB)\n",
            "Downloading llama_index_llms_openai-0.6.5-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_readers_web-0.5.5-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading firecrawl_py-4.5.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.4/171.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_workflows-2.8.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading markdownify-1.2.0-py3-none-any.whl (15 kB)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oxylabs-2.0.0-py3-none-any.whl (34 kB)\n",
            "Downloading playwright-1.55.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.37.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading weaviate_agents-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading weaviate_client-4.17.0-py3-none-any.whl (582 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.8/582.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: html2text, tinysegmenter, spider-client, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=2894ae2f26a87633090f0744b0ad795dcf6eeebe462877ac2227f4a3b97566d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/01/23/578505d65e2a97d78bf1fe3fc8256ecf37572dc1df598b0eaf\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=0390db43f852169955ddf99ccf8cb701a53f974fc3cbed3727311a8424aa0994\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spider-client: filename=spider_client-0.0.27-py3-none-any.whl size=5975 sha256=e267a07abe631f50d29614314c0cfe8af1988e34b676794f22c98de3bd514abf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/41/42/4155300999390be7e455a6b05c602849f5810bf9383c43adb2\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=b13986a27ede4d7f37c64730e2a59365387711c1fec8920bbff3867540b4bef8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=fff48e868ca75320bf74932bdb945a56d5696862ed02c1d61653bd34b41b94d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=05e09f9487da2855922f836d5c0f6bea7a108a705130473ab390bddeb0b66218\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built html2text tinysegmenter spider-client feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, filetype, dirtyjson, wsproto, wrapt, validators, setuptools, pyee, outcome, mypy-extensions, marshmallow, lxml-html-clean, jedi, html2text, feedparser, deprecation, cssselect, colorama, chromedriver-autoinstaller, aiosqlite, typing-inspect, trio, spider-client, requests-file, playwright, markdownify, griffe, feedfinder2, deprecated, trio-websocket, tldextract, pyvis, oxylabs, llama-index-instrumentation, firecrawl-py, dataclasses-json, banks, weaviate-client, selenium, newspaper3k, llama-index-workflows, weaviate-agents, llama-index-core, llama-index-utils-workflow, llama-index-readers-web, llama-index-llms-openai\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.0\n",
            "    Uninstalling wrapt-2.0.0:\n",
            "      Successfully uninstalled wrapt-2.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "Successfully installed aiosqlite-0.21.0 banks-2.2.0 chromedriver-autoinstaller-0.6.4 colorama-0.4.6 cssselect-1.3.0 dataclasses-json-0.6.7 deprecated-1.2.18 deprecation-2.1.0 dirtyjson-1.0.8 feedfinder2-0.0.4 feedparser-6.0.12 filetype-1.2.0 firecrawl-py-4.5.0 griffe-1.14.0 html2text-2024.2.26 jedi-0.19.2 jieba3k-0.35.1 llama-index-core-0.14.5 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.5 llama-index-readers-web-0.5.5 llama-index-utils-workflow-0.4.1 llama-index-workflows-2.8.3 lxml-html-clean-0.4.3 markdownify-1.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 newspaper3k-0.2.8 outcome-1.3.0.post0 oxylabs-2.0.0 playwright-1.55.0 pyee-13.0.0 pyvis-0.3.2 requests-file-3.0.1 selenium-4.37.0 setuptools-80.9.0 sgmllib3k-1.0.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.3.0 trio-0.31.0 trio-websocket-0.12.2 typing-inspect-0.9.0 validators-0.35.0 weaviate-agents-1.1.0 weaviate-client-4.17.0 wrapt-1.17.3 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "813d9f3f7e584f5ebf23e605ad64e1aa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install llama-index-core llama-index-utils-workflow weaviate-client[agents] llama-index-llms-openai llama-index-readers-web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th6AvFSbKOo9"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.workflow import (\n",
        "    StartEvent,\n",
        "    StopEvent,\n",
        "    Workflow,\n",
        "    step,\n",
        "    Event,\n",
        "    Context,\n",
        ")\n",
        "from llama_index.utils.workflow import draw_all_possible_flows\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.agent.workflow import FunctionAgent\n",
        "\n",
        "from enum import Enum\n",
        "from pydantic import BaseModel, Field\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from typing import List, Union\n",
        "import json\n",
        "\n",
        "import weaviate\n",
        "from weaviate.auth import Auth\n",
        "from weaviate.agents.query import QueryAgent\n",
        "from weaviate.classes.config import Configure, Property, DataType\n",
        "\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsER-HrEKOo9"
      },
      "source": [
        "## Set up Weaviate\n",
        "\n",
        "To use the Weaviate Query Agent, first, create a [Weaviate Cloud](https://weaviate.io/deployment/serverless) account👇\n",
        "1. [Create Serverless Weaviate Cloud account](https://weaviate.io/deployment/serverless) and set up a free [Sandbox](https://weaviate.io/developers/wcs/manage-clusters/create#sandbox-clusters)\n",
        "2. Go to 'Embedding' and enable it, by default, this will make it so that we use `Snowflake/snowflake-arctic-embed-l-v2.0` as the embedding model\n",
        "3. Take note of the `WEAVIATE_URL` and `WEAVIATE_API_KEY` to connect to your cluster below\n",
        "\n",
        "> Info: We recommend using [Weaviate Embeddings](https://weaviate.io/developers/weaviate/model-providers/weaviate) so you do not have to provide any extra keys for external embedding providers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ6uWyugKOo-"
      },
      "outputs": [],
      "source": [
        "if \"WEAVIATE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"WEAVIATE_API_KEY\"] = getpass(\"Add Weaviate API Key\")\n",
        "if \"WEAVIATE_URL\" not in os.environ:\n",
        "    os.environ[\"WEAVIATE_URL\"] = getpass(\"Add Weaviate URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7LqrvxdKOo-"
      },
      "outputs": [],
      "source": [
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=os.environ.get(\"WEAVIATE_URL\"),\n",
        "    auth_credentials=Auth.api_key(os.environ.get(\"WEAVIATE_API_KEY\")),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8U4OTCKOo-"
      },
      "source": [
        "### Create WeaviateDocs and LlamaIndexDocs Collections\n",
        "\n",
        "The helper function below will create a \"WeaviateDocs\" and \"LlamaIndexDocs\" collection in Weaviate (if they don't exist already). It will also set up a `QueryAgent` that has access to both of these collections.\n",
        "\n",
        "The Weaviate [`QueryAgent`](https://weaviate.io/blog/query-agent) is designed to be able to query Weviate Collections for both regular search and aggregations, and also handles the burden of creating the Weaviate specific queries internally.\n",
        "\n",
        "The Agent will use the collection descriptions, as well as the property descriptions while formilating the queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TdljU3cKOo-"
      },
      "outputs": [],
      "source": [
        "def fresh_setup_weaviate(client):\n",
        "    if client.collections.exists(\"WeaviateDocs\"):\n",
        "        client.collections.delete(\"WeaviateDocs\")\n",
        "    client.collections.create(\n",
        "        \"WeaviateDocs\",\n",
        "        description=\"A dataset with the contents of Weaviate technical Docs and website\",\n",
        "        vectorizer_config=Configure.Vectorizer.text2vec_weaviate(),\n",
        "        properties=[\n",
        "            Property(\n",
        "                name=\"url\",\n",
        "                data_type=DataType.TEXT,\n",
        "                description=\"the source URL of the webpage\",\n",
        "            ),\n",
        "            Property(\n",
        "                name=\"text\",\n",
        "                data_type=DataType.TEXT,\n",
        "                description=\"the content of the webpage\",\n",
        "            ),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    if client.collections.exists(\"LlamaIndexDocs\"):\n",
        "        client.collections.delete(\"LlamaIndexDocs\")\n",
        "    client.collections.create(\n",
        "        \"LlamaIndexDocs\",\n",
        "        description=\"A dataset with the contents of LlamaIndex technical Docs and website\",\n",
        "        vectorizer_config=Configure.Vectorizer.text2vec_weaviate(),\n",
        "        properties=[\n",
        "            Property(\n",
        "                name=\"url\",\n",
        "                data_type=DataType.TEXT,\n",
        "                description=\"the source URL of the webpage\",\n",
        "            ),\n",
        "            Property(\n",
        "                name=\"text\",\n",
        "                data_type=DataType.TEXT,\n",
        "                description=\"the content of the webpage\",\n",
        "            ),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    agent = QueryAgent(\n",
        "        client=client, collections=[\"LlamaIndexDocs\", \"WeaviateDocs\"]\n",
        "    )\n",
        "    return agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrrwGrcRKOo-"
      },
      "source": [
        "### Write Contents of Webpage to the Collections\n",
        "\n",
        "The helper function below uses the `SimpleWebPageReader` to write the contents of a webpage to the relevant Weaviate collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLjsiQ8VKOo-"
      },
      "outputs": [],
      "source": [
        "def write_webpages_to_weaviate(client, urls: list[str], collection_name: str):\n",
        "    documents = SimpleWebPageReader(html_to_text=True).load_data(urls)\n",
        "    collection = client.collections.get(collection_name)\n",
        "    with collection.batch.dynamic() as batch:\n",
        "        for doc in documents:\n",
        "            batch.add_object(properties={\"url\": doc.id_, \"text\": doc.text})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqDGwbmYKOo-"
      },
      "source": [
        "## Create a Function Calling Agent\n",
        "\n",
        "Now that we have the relevant functions to write to a collection and also the `QueryAgent` at hand, we can start by using the `FunctionAgent`, which is a simple tool calling agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAWrlSLiKOo-"
      },
      "outputs": [],
      "source": [
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"openai-key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zro_5bheKOo-"
      },
      "outputs": [],
      "source": [
        "weaviate_agent = fresh_setup_weaviate(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb0CPcERKOo-"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "\n",
        "def write_to_weaviate_collection(urls=list[str]):\n",
        "    \"\"\"Useful for writing new content to the WeaviateDocs collection\"\"\"\n",
        "    write_webpages_to_weaviate(client, urls, \"WeaviateDocs\")\n",
        "\n",
        "\n",
        "def write_to_li_collection(urls=list[str]):\n",
        "    \"\"\"Useful for writing new content to the LlamaIndexDocs collection\"\"\"\n",
        "    write_webpages_to_weaviate(client, urls, \"LlamaIndexDocs\")\n",
        "\n",
        "\n",
        "def query_agent(query: str) -> str:\n",
        "    \"\"\"Useful for asking questions about Weaviate and LlamaIndex\"\"\"\n",
        "    response = weaviate_agent.run(query)\n",
        "    return response.final_answer\n",
        "\n",
        "\n",
        "agent = FunctionAgent(\n",
        "    tools=[write_to_weaviate_collection, write_to_li_collection, query_agent],\n",
        "    llm=llm,\n",
        "    system_prompt=\"\"\"You are a helpful assistant that can write the\n",
        "      contents of urls to WeaviateDocs and LlamaIndexDocs collections,\n",
        "      as well as forwarding questions to a QueryAgent\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-_3-rcxKOo-"
      },
      "outputs": [],
      "source": [
        "response = await agent.run(\n",
        "    user_msg=\"Can you save https://docs.llamaindex.ai/en/stable/examples/agent/agent_workflow_basic/\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G4WU6btKOo_",
        "outputId": "ece7ed69-5055-466e-b5e4-6b1942f902c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama Index workflows refer to orchestrations involving one or more AI agents within the LlamaIndex framework. These workflows manage complex tasks dynamically by leveraging components such as large language models (LLMs), tools, and memory states. Key features of Llama Index workflows include:\n",
            "\n",
            "- Support for single or multiple agents managed within an AgentWorkflow orchestrator.\n",
            "- Ability to maintain state across runs via serializable context objects.\n",
            "- Integration of external tools with type annotations, including asynchronous functions.\n",
            "- Streaming of intermediate outputs and event-based interactions.\n",
            "- Human-in-the-loop capabilities to confirm or guide agent actions during workflow execution.\n",
            "\n",
            "These workflows enable agents to execute sequences of operations, call external tools asynchronously, maintain conversation or task states, stream partial results, and incorporate human inputs when necessary. They embody dynamic, agent-driven sequences of task decomposition, tool use, and reflection, allowing AI systems to plan, act, and improve iteratively toward specific goals.\n",
            "\n",
            "I have also saved the contents from the provided URLs to the WeaviateDocs collection.\n"
          ]
        }
      ],
      "source": [
        "response = await agent.run(\n",
        "    user_msg=\"\"\"What are llama index workflows? And can you save\n",
        "    these to weaviate docs: https://weaviate.io/blog/what-are-agentic-workflows\n",
        "    and https://weaviate.io/blog/ai-agents\"\"\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1eO0HBmKOo_",
        "outputId": "557d9a77-055a-496d-e47f-fbad0d076a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have a total of 2 documents in the WeaviateDocs collection and 1 document in the LlamaIndexDocs collection. In total, that makes 3 documents across both collections.\n"
          ]
        }
      ],
      "source": [
        "response = await agent.run(\n",
        "    user_msg=\"How many docs do I have in the weaviate and llamaindex collections in total?\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOzqkScFKOo_"
      },
      "outputs": [],
      "source": [
        "weaviate_agent = fresh_setup_weaviate(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZkg7r2KOo_"
      },
      "source": [
        "## Create a Workflow with Branches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRknt-NAKOo_"
      },
      "source": [
        "### Simple Example: Create Events\n",
        "\n",
        "A LlamaIndex Workflow has 2 fundamentals:\n",
        "- An Event\n",
        "- A Step\n",
        "\n",
        "An step may return an event, and an event may trigger a step!\n",
        "\n",
        "For our use-case, we can imagine thet there are 4 events:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHDmyeQEKOo_"
      },
      "outputs": [],
      "source": [
        "class EvaluateQuery(Event):\n",
        "    query: str\n",
        "\n",
        "\n",
        "class WriteLlamaIndexDocsEvent(Event):\n",
        "    urls: list[str]\n",
        "\n",
        "\n",
        "class WriteWeaviateDocsEvent(Event):\n",
        "    urls: list[str]\n",
        "\n",
        "\n",
        "class QueryAgentEvent(Event):\n",
        "    query: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUQ4eX1vKOo_"
      },
      "source": [
        "### Simple Example: A Branching Workflow (that does nothing yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LhISg-PKOo_"
      },
      "outputs": [],
      "source": [
        "class DocsAssistantWorkflow(Workflow):\n",
        "    @step\n",
        "    async def start(self, ctx: Context, ev: StartEvent) -> EvaluateQuery:\n",
        "        return EvaluateQuery(query=ev.query)\n",
        "\n",
        "    @step\n",
        "    async def evaluate_query(\n",
        "        self, ctx: Context, ev: EvaluateQuery\n",
        "    ) -> QueryAgentEvent | WriteLlamaIndexDocsEvent | WriteWeaviateDocsEvent | StopEvent:\n",
        "        if ev.query == \"llama\":\n",
        "            return WriteLlamaIndexDocsEvent(urls=[ev.query])\n",
        "        if ev.query == \"weaviate\":\n",
        "            return WriteWeaviateDocsEvent(urls=[ev.query])\n",
        "        if ev.query == \"question\":\n",
        "            return QueryAgentEvent(query=ev.query)\n",
        "        return StopEvent()\n",
        "\n",
        "    @step\n",
        "    async def write_li_docs(\n",
        "        self, ctx: Context, ev: WriteLlamaIndexDocsEvent\n",
        "    ) -> StopEvent:\n",
        "        print(f\"Got a request to write something to LlamaIndexDocs\")\n",
        "        return StopEvent()\n",
        "\n",
        "    @step\n",
        "    async def write_weaviate_docs(\n",
        "        self, ctx: Context, ev: WriteWeaviateDocsEvent\n",
        "    ) -> StopEvent:\n",
        "        print(f\"Got a request to write something to WeaviateDocs\")\n",
        "        return StopEvent()\n",
        "\n",
        "    @step\n",
        "    async def query_agent(\n",
        "        self, ctx: Context, ev: QueryAgentEvent\n",
        "    ) -> StopEvent:\n",
        "        print(f\"Got a request to forward a query to the QueryAgent\")\n",
        "        return StopEvent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHtIz5lUKOo_"
      },
      "outputs": [],
      "source": [
        "workflow_that_does_nothing = DocsAssistantWorkflow()\n",
        "\n",
        "# draw_all_possible_flows(workflow_that_does_nothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGOEK2tpKOo_",
        "outputId": "42bb691f-1f97-421b-8d9a-d4455416ce09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got a request to write something to LlamaIndexDocs\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    await workflow_that_does_nothing.run(start_event=StartEvent(query=\"llama\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0SyNhDLKOo_"
      },
      "source": [
        "### Classify the Query with Structured Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgEse6U8KOo_"
      },
      "outputs": [],
      "source": [
        "class SaveToLlamaIndexDocs(BaseModel):\n",
        "    \"\"\"The URLs to parse and save into a llama-index specific docs collection.\"\"\"\n",
        "\n",
        "    llama_index_urls: List[str] = Field(default_factory=list)\n",
        "\n",
        "\n",
        "class SaveToWeaviateDocs(BaseModel):\n",
        "    \"\"\"The URLs to parse and save into a weaviate specific docs collection.\"\"\"\n",
        "\n",
        "    weaviate_urls: List[str] = Field(default_factory=list)\n",
        "\n",
        "\n",
        "class Ask(BaseModel):\n",
        "    \"\"\"The natural language questions that can be asked to a Q&A agent.\"\"\"\n",
        "\n",
        "    queries: List[str] = Field(default_factory=list)\n",
        "\n",
        "\n",
        "class Actions(BaseModel):\n",
        "    \"\"\"Actions to take based on the latest user message.\"\"\"\n",
        "\n",
        "    actions: List[\n",
        "        Union[SaveToLlamaIndexDocs, SaveToWeaviateDocs, Ask]\n",
        "    ] = Field(default_factory=list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FCPMbo7KOo_"
      },
      "source": [
        "#### Create a Workflow\n",
        "\n",
        "Let's create a workflow that, still, does nothing, but the incoming user query will be converted to our structure. Based on the contents of that structure, the workflow will decide which step to run.\n",
        "\n",
        "Notice how whichever step runs first, will return a `StopEvent`... This is good, but maybe we can improve that later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1N758-kKOo_"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAIResponses\n",
        "\n",
        "\n",
        "class DocsAssistantWorkflow(Workflow):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.llm = OpenAIResponses(model=\"gpt-4.1-mini\")\n",
        "        self.system_prompt = \"\"\"You are a docs assistant. You evaluate incoming queries and break them down to subqueries when needed.\n",
        "                          You decide on the next best course of action. Overall, here are the options:\n",
        "                          - You can write the contents of a URL to llamaindex docs (if it's a llamaindex url)\n",
        "                          - You can write the contents of a URL to weaviate docs (if it's a weaviate url)\n",
        "                          - You can answer a question about llamaindex and weaviate using the QueryAgent\"\"\"\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    @step\n",
        "    async def start(self, ev: StartEvent) -> EvaluateQuery:\n",
        "        return EvaluateQuery(query=ev.query)\n",
        "\n",
        "    @step\n",
        "    async def evaluate_query(\n",
        "        self, ev: EvaluateQuery\n",
        "    ) -> QueryAgentEvent | WriteLlamaIndexDocsEvent | WriteWeaviateDocsEvent:\n",
        "        sllm = self.llm.as_structured_llm(Actions)\n",
        "        response = await sllm.achat(\n",
        "            [\n",
        "                ChatMessage(role=\"system\", content=self.system_prompt),\n",
        "                ChatMessage(role=\"user\", content=ev.query),\n",
        "            ]\n",
        "        )\n",
        "        actions = response.raw.actions\n",
        "        print(actions)\n",
        "        for action in actions:\n",
        "            if isinstance(action, SaveToLlamaIndexDocs):\n",
        "                return WriteLlamaIndexDocsEvent(urls=action.llama_index_urls)\n",
        "            elif isinstance(action, SaveToWeaviateDocs):\n",
        "                return WriteWeaviateDocsEvent(urls=action.weaviate_urls)\n",
        "            elif isinstance(action, Ask):\n",
        "                for query in action.queries:\n",
        "                    return QueryAgentEvent(query=query)\n",
        "\n",
        "    @step\n",
        "    async def write_li_docs(self, ev: WriteLlamaIndexDocsEvent) -> StopEvent:\n",
        "        print(f\"Writing {ev.urls} to LlamaIndex Docs\")\n",
        "        return StopEvent()\n",
        "\n",
        "    @step\n",
        "    async def write_weaviate_docs(\n",
        "        self, ev: WriteWeaviateDocsEvent\n",
        "    ) -> StopEvent:\n",
        "        print(f\"Writing {ev.urls} to Weaviate Docs\")\n",
        "        return StopEvent()\n",
        "\n",
        "    @step\n",
        "    async def query_agent(self, ev: QueryAgentEvent) -> StopEvent:\n",
        "        print(f\"Sending `'{ev.query}`' to agent\")\n",
        "        return StopEvent()\n",
        "\n",
        "\n",
        "everything_docs_agent_beta = DocsAssistantWorkflow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbJSiPb_KOo_"
      },
      "outputs": [],
      "source": [
        "async def run_docs_agent_beta(query: str):\n",
        "    print(\n",
        "        await everything_docs_agent_beta.run(\n",
        "            start_event=StartEvent(query=query)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_2o-T1VKOo_",
        "outputId": "c72e3424-ed4d-4e5b-a767-a524cb681197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SaveToLlamaIndexDocs(llama_index_urls=['https://www.llamaindex.ai/blog/get-citations-and-reasoning-for-extracted-data-in-llamaextract', 'https://www.llamaindex.ai/blog/llamaparse-update-may-2025-new-models-skew-detection-and-more'])]\n",
            "Writing ['https://www.llamaindex.ai/blog/get-citations-and-reasoning-for-extracted-data-in-llamaextract', 'https://www.llamaindex.ai/blog/llamaparse-update-may-2025-new-models-skew-detection-and-more'] to LlamaIndex Docs\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent_beta(\n",
        "    \"\"\"Can you save https://www.llamaindex.ai/blog/get-citations-and-reasoning-for-extracted-data-in-llamaextract\n",
        "    and https://www.llamaindex.ai/blog/llamaparse-update-may-2025-new-models-skew-detection-and-more??\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B4GO5NaKOo_",
        "outputId": "c237909a-b61f-452d-864a-c88142756598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Ask(queries=['How many documents are in the LlamaIndexDocs collection?'])]\n",
            "Sending `'How many documents are in the LlamaIndexDocs collection?`' to agent\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent_beta(\n",
        "    \"How many documents do we have in the LlamaIndexDocs collection now?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ30k412KOo_",
        "outputId": "ff45f06e-e378-478a-c1c8-65d13d082051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Ask(queries=['What are LlamaIndex workflows?'])]\n",
            "Sending `'What are LlamaIndex workflows?`' to agent\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent_beta(\"What are LlamaIndex workflows?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHDgN-eyKOpA",
        "outputId": "32f853e5-cf74-4411-c912-a152a839015e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SaveToWeaviateDocs(weaviate_urls=['https://weaviate.io/blog/graph-rag', 'https://weaviate.io/blog/genai-apps-with-weaviate-and-databricks'])]\n",
            "Writing ['https://weaviate.io/blog/graph-rag', 'https://weaviate.io/blog/genai-apps-with-weaviate-and-databricks'] to Weaviate Docs\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent_beta(\n",
        "    \"Can you save https://weaviate.io/blog/graph-rag and https://weaviate.io/blog/genai-apps-with-weaviate-and-databricks??\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auysL2ytKOpA"
      },
      "source": [
        "## Run Multiple Branches & Put it all togehter\n",
        "\n",
        "In these cases, it makes sense to run multiple branches. So, a single step can trigger multiple events at once! We can `send_event` via the context 👇"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpd-pkzrKOpA"
      },
      "outputs": [],
      "source": [
        "class ActionCompleted(Event):\n",
        "    result: str\n",
        "\n",
        "\n",
        "class DocsAssistantWorkflow(Workflow):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.llm = OpenAIResponses(model=\"gpt-4.1-mini\")\n",
        "        self.system_prompt = \"\"\"You are a docs assistant. You evaluate incoming queries and break them down to subqueries when needed.\n",
        "                      You decide on the next best course of action. Overall, here are the options:\n",
        "                      - You can write the contents of a URL to llamaindex docs (if it's a llamaindex url)\n",
        "                      - You can write the contents of a URL to weaviate docs (if it's a weaviate url)\n",
        "                      - You can answer a question about llamaindex and weaviate using the QueryAgent\"\"\"\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    @step\n",
        "    async def start(self, ctx: Context, ev: StartEvent) -> EvaluateQuery:\n",
        "        return EvaluateQuery(query=ev.query)\n",
        "\n",
        "    @step\n",
        "    async def evaluate_query(\n",
        "        self, ctx: Context, ev: EvaluateQuery\n",
        "    ) -> QueryAgentEvent | WriteLlamaIndexDocsEvent | WriteWeaviateDocsEvent | None:\n",
        "        await ctx.store.set(\"results\", [])\n",
        "        sllm = self.llm.as_structured_llm(Actions)\n",
        "        response = await sllm.achat(\n",
        "            [\n",
        "                ChatMessage(role=\"system\", content=self.system_prompt),\n",
        "                ChatMessage(role=\"user\", content=ev.query),\n",
        "            ]\n",
        "        )\n",
        "        actions = response.raw.actions\n",
        "        await ctx.store.set(\"num_events\", len(actions))\n",
        "        await ctx.store.set(\"results\", [])\n",
        "        print(actions)\n",
        "        for action in actions:\n",
        "            if isinstance(action, SaveToLlamaIndexDocs):\n",
        "                ctx.send_event(\n",
        "                    WriteLlamaIndexDocsEvent(urls=action.llama_index_urls)\n",
        "                )\n",
        "            elif isinstance(action, SaveToWeaviateDocs):\n",
        "                ctx.send_event(\n",
        "                    WriteWeaviateDocsEvent(urls=action.weaviate_urls)\n",
        "                )\n",
        "            elif isinstance(action, Ask):\n",
        "                for query in action.queries:\n",
        "                    ctx.send_event(QueryAgentEvent(query=query))\n",
        "\n",
        "    @step\n",
        "    async def write_li_docs(\n",
        "        self, ctx: Context, ev: WriteLlamaIndexDocsEvent\n",
        "    ) -> ActionCompleted:\n",
        "        print(f\"Writing {ev.urls} to LlamaIndex Docs\")\n",
        "        write_webpages_to_weaviate(\n",
        "            client, urls=ev.urls, collection_name=\"LlamaIndexDocs\"\n",
        "        )\n",
        "        results = await ctx.store.get(\"results\")\n",
        "        results.append(f\"Wrote {ev.urls} it LlamaIndex Docs\")\n",
        "        return ActionCompleted(result=f\"Writing {ev.urls} to LlamaIndex Docs\")\n",
        "\n",
        "    @step\n",
        "    async def write_weaviate_docs(\n",
        "        self, ctx: Context, ev: WriteWeaviateDocsEvent\n",
        "    ) -> ActionCompleted:\n",
        "        print(f\"Writing {ev.urls} to Weaviate Docs\")\n",
        "        write_webpages_to_weaviate(\n",
        "            client, urls=ev.urls, collection_name=\"WeaviateDocs\"\n",
        "        )\n",
        "        results = await ctx.store.get(\"results\")\n",
        "        results.append(f\"Wrote {ev.urls} it Weavite Docs\")\n",
        "        return ActionCompleted(result=f\"Writing {ev.urls} to Weaviate Docs\")\n",
        "\n",
        "    @step\n",
        "    async def query_agent(\n",
        "        self, ctx: Context, ev: QueryAgentEvent\n",
        "    ) -> ActionCompleted:\n",
        "        print(f\"Sending {ev.query} to agent\")\n",
        "        response = weaviate_agent.run(ev.query)\n",
        "        results = await ctx.store.get(\"results\")\n",
        "        results.append(f\"QueryAgent responded with:\\n {response.final_answer}\")\n",
        "        return ActionCompleted(result=f\"Sending `'{ev.query}`' to agent\")\n",
        "\n",
        "    @step\n",
        "    async def collect(\n",
        "        self, ctx: Context, ev: ActionCompleted\n",
        "    ) -> StopEvent | None:\n",
        "        num_events = await ctx.store.get(\"num_events\")\n",
        "        evs = ctx.collect_events(ev, [ActionCompleted] * num_events)\n",
        "        if evs is None:\n",
        "            return None\n",
        "        return StopEvent(result=[ev.result for ev in evs])\n",
        "\n",
        "\n",
        "everything_docs_agent = DocsAssistantWorkflow(timeout=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu2Wg9DsKOpC"
      },
      "outputs": [],
      "source": [
        "async def run_docs_agent(query: str):\n",
        "    handler = everything_docs_agent.run(start_event=StartEvent(query=query))\n",
        "    result = await handler\n",
        "    for response in await handler.ctx.store.get(\"results\"):\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zeDdlLnKOpC",
        "outputId": "2ffcad8a-4692-4b5c-e4a3-a25591785dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SaveToLlamaIndexDocs(llama_index_urls=['https://docs.llamaindex.ai/en/stable/understanding/workflows/']), SaveToLlamaIndexDocs(llama_index_urls=['https://docs.llamaindex.ai/en/stable/understanding/workflows/branches_and_loops/'])]\n",
            "Writing ['https://docs.llamaindex.ai/en/stable/understanding/workflows/'] to LlamaIndex Docs\n",
            "Writing ['https://docs.llamaindex.ai/en/stable/understanding/workflows/branches_and_loops/'] to LlamaIndex Docs\n",
            "Wrote ['https://docs.llamaindex.ai/en/stable/understanding/workflows/'] it LlamaIndex Docs\n",
            "Wrote ['https://docs.llamaindex.ai/en/stable/understanding/workflows/branches_and_loops/'] it LlamaIndex Docs\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent(\n",
        "    \"Can you save https://docs.llamaindex.ai/en/stable/understanding/workflows/ and https://docs.llamaindex.ai/en/stable/understanding/workflows/branches_and_loops/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvYn0fYGKOpC",
        "outputId": "d9afca8e-5f4b-4dea-96d2-3844b720c4ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Ask(queries=['How many documents are in the LlamaIndexDocs collection?'])]\n",
            "Sending How many documents are in the LlamaIndexDocs collection? to agent\n",
            "QueryAgent responded with:\n",
            " The LlamaIndexDocs collection contains 2 documents, specifically related to workflows and branches and loops within the documentation.\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent(\n",
        "    \"How many documents do we have in the LlamaIndexDocs collection now?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrh6cWEEKOpC",
        "outputId": "ef3afb84-649f-4740-e1c6-9059b9922aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Ask(queries=['What are LlamaIndex workflows?'])]\n",
            "Sending What are LlamaIndex workflows? to agent\n",
            "QueryAgent responded with:\n",
            " LlamaIndex workflows are an event-driven, step-based framework designed to control and manage the execution flow of complex applications, particularly those involving generative AI. They break an application into discrete Steps, each triggered by Events and capable of emitting further Events, allowing for complex logic involving loops, branches, and parallel execution.\n",
            "\n",
            "In a LlamaIndex workflow, steps perform functions ranging from simple tasks to complex agents, with inputs and outputs communicated via Events. This event-driven model facilitates maintainability and clarity, overcoming limitations of previous approaches like directed acyclic graphs (DAGs) which struggled with complex flows involving loops and branching.\n",
            "\n",
            "Key features include:\n",
            "- **Loops:** Steps can return events that loop back to previous steps to enable iterative processes.\n",
            "- **Branches:** Workflows can branch into different paths based on conditions, allowing for multiple distinct sequences of steps.\n",
            "- **Parallelism:** Multiple branches or steps can run concurrently and synchronize their results.\n",
            "- **State Maintenance:** Workflows support maintaining state and context throughout execution.\n",
            "- **Observability and Debugging:** Supported by various components and callbacks for monitoring.\n",
            "\n",
            "An example workflow might involve judging whether a query is of sufficient quality, looping to improve it if not, then concurrently executing different retrieval-augmented generation (RAG) strategies, and finally judging their responses to produce a single output.\n",
            "\n",
            "Workflows are especially useful as applications grow in complexity, enabling developers to organize and control intricate AI logic more naturally and efficiently than traditional graph-based methods. For simpler pipelines, LlamaIndex suggests using workflows optionally, but for advanced agentic applications, workflows provide a flexible and powerful control abstraction.\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent(\n",
        "    \"What are LlamaIndex workflows? And can you save https://weaviate.io/blog/graph-rag\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BexLfbqAKOpC",
        "outputId": "6205ebee-0bfb-4bce-fe1e-84077f30b519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Ask(queries=['How to use loops in llamaindex workflows'])]\n",
            "Sending How to use loops in llamaindex workflows to agent\n",
            "QueryAgent responded with:\n",
            " In LlamaIndex workflows, loops are implemented using an event-driven approach where you define custom event types and steps that emit events to control the workflow's execution flow. To create a loop, you define a custom event (e.g., `LoopEvent`) and a workflow step that can return either the event continuing the loop or another event to proceed. For example, a workflow step might randomly decide to either loop back (emit `LoopEvent` again) or continue to a next step emitting a different event.\n",
            "\n",
            "This allows creating flexible looping behaviors where any step can loop back to any other step by returning the corresponding event instances. The approach leverages Python's async functions decorated with `@step`, which process events and return the next event(s), enabling both loops and conditional branching in workflows.\n",
            "\n",
            "Thus, loops in LlamaIndex workflows are event-based, using custom event types and the return of events from steps to signal iterations until a condition is met.\n",
            "\n",
            "Example:\n",
            "\n",
            "```python\n",
            "from llamaindex.workflow import Workflow, Event, StartEvent, StopEvent, step\n",
            "import random\n",
            "\n",
            "class LoopEvent(Event):\n",
            "    loop_output: str\n",
            "\n",
            "class FirstEvent(Event):\n",
            "    first_output: str\n",
            "\n",
            "class MyWorkflow(Workflow):\n",
            "    @step\n",
            "    async def step_one(self, ev: StartEvent | LoopEvent) -> FirstEvent | LoopEvent:\n",
            "        if random.randint(0, 1) == 0:\n",
            "            print(\"Bad thing happened\")\n",
            "            return LoopEvent(loop_output=\"Back to step one.\")\n",
            "        else:\n",
            "            print(\"Good thing happened\")\n",
            "            return FirstEvent(first_output=\"First step complete.\")\n",
            "\n",
            "    # ... other steps ...\n",
            "\n",
            "# Running this workflow will cause step_one to loop randomly until it proceeds.\n",
            "```\n",
            "\n",
            "You can combine loops with branching and parallel execution in workflows to build complex control flows. For detailed guidance and examples, consult the LlamaIndex documentation under \"Branches and Loops\" and the \"Workflows\" guides.\n"
          ]
        }
      ],
      "source": [
        "await run_docs_agent(\"How do I use loops in llamaindex workflows?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rurysjPlqCae",
        "wt0MVTTkrR4e",
        "eHQHV4szr1WX",
        "pQOukan2wQZ0",
        "GDtnnETPzsAC"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}